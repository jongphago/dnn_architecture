{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"my_timeseries.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"18v0WlUcKXaLXHMcO01EsKCG3KSv-qn3t","authorship_tag":"ABX9TyOhVybYSzLXr3/CV1448b8f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7rZnJaGTWQw0"},"source":["import os\n","import datetime\n","\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vMmqZGbMnzvg"},"source":["## 날씨 데이터세트"]},{"cell_type":"code","metadata":{"id":"m405B-_Fe-Xv"},"source":["# data_path = '/content/drive/MyDrive/Colab_Timeseries/data/sample.csv'\n","data_path = '/content/drive/MyDrive/Colab_Architecture/data/ASOS_108_20090101_20161231.csv'\n","_null_df = pd.read_csv(data_path)\n","null_df = _null_df.drop(columns=['Unnamed: 0'])\n","df = null_df.interpolate()\n","df.drop(columns=['rnum', 'stnId', 'stnNm'], inplace=True)\n","date_time = pd.to_datetime(df.pop('tm'), format='%Y-%m-%d %H:%M')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFkO2W7onzNF"},"source":["is_null = df.isnull().sum().sum()\n","if not is_null:\n","    display(df.head())\n","else:\n","    print(\"결측치가 완전히 처리되지 않았습니다.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlaMB03Bmo27"},"source":["date_time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nCWjpmrn3Nu"},"source":["plot_cols = ['ta', 'pa', 'hm']\n","plot_features = df[plot_cols]\n","plot_features.index = date_time\n","_ = plot_features.plot(subplots=True)\n","\n","plot_features = df[plot_cols][:480]\n","plot_features.index = date_time[:480]\n","_ = plot_features.plot(subplots=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXWLG0_WBhZS"},"source":["### 검사 및 정리하기"]},{"cell_type":"markdown","metadata":{"id":"yhmZXJew6GlS"},"source":["다음으로 데이터세트의 통계를 살펴봅니다."]},{"cell_type":"code","metadata":{"id":"h510pgKVrrai"},"source":["df.describe().transpose()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vtmu2IBPgPG8"},"source":["### 특성 엔지니어링\n","\n","모델을 본격적으로 빌드하기 전에 데이터를 이해하고 모델에 적절한 형식의 데이터를 전달하는 것이 중요합니다."]},{"cell_type":"code","metadata":{"id":"-f5kCAtMaSil"},"source":["df['rn'].plot.hist()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FYyEaqiD6j4s"},"source":["#### 바람\n","\n","데이터의 마지막 열인 `wd (deg)`는 도 단위로 바람의 방향을 나타냅니다. 각도가 있으면 모델 입력으로 좋지 않으므로 360°와 0°는 서로 가까워야 하며 부드럽게 휘어져야 합니다. 바람이 불지 않으면 방향은 중요하지 않습니다.\n","\n","현재, 바람 데이터의 분포는 다음과 같습니다."]},{"cell_type":"code","metadata":{"id":"YO7JGTcWQG2z"},"source":["plt.hist2d(df['wd'], df['ws'], bins=(50, 50), vmax=400)\n","plt.colorbar()\n","plt.xlabel('Wind Direction [deg]')\n","plt.ylabel('Wind Velocity [m/s]')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yWnf5dwMU1_g"},"source":["그러나 풍향과 속도 열을 바람 **벡터**로 변환하면 모델이 해석하기가 더 쉽습니다."]},{"cell_type":"code","metadata":{"id":"6GmSTHXw6lI1"},"source":["wv = df.pop('ws')\n","\n","# Convert to radians.\n","wd_rad = df.pop('wd')*np.pi / 180\n","\n","# Calculate the wind x and y components.\n","df['Wx'] = wv*np.cos(wd_rad)\n","df['Wy'] = wv*np.sin(wd_rad)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7iI0zDoxWDyB"},"source":["바람 벡터의 분포는 모델이 올바르게 해석하기에 훨씬 더 간단합니다."]},{"cell_type":"code","metadata":{"id":"bMgCG5o2SYKD"},"source":["plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n","plt.colorbar()\n","plt.xlabel('Wind X [m/s]')\n","plt.ylabel('Wind Y [m/s]')\n","ax = plt.gca()\n","ax.axis('tight')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_8im1ttOWlRB"},"source":["#### 시간"]},{"cell_type":"markdown","metadata":{"id":"7YE21HKK40zQ"},"source":["마찬가지로 `Date Time` 열은 매우 유용하지만 이 문자열 형식으로는 유용하지 않습니다. 우선 초로 변환합니다."]},{"cell_type":"code","metadata":{"id":"LIFf-VjMfnh3"},"source":["timestamp_s = date_time.map(datetime.datetime.timestamp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zds9HZg1zB16"},"source":["timestamp_s"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EC_pnM1D5Sgc"},"source":["풍향과 유사하게 초 단위의 시간은 유용한 모델 입력이 아닙니다. 날씨 데이터이므로 하루 및 연 단위의 주기성이 명확합니다. 주기성을 처리할 수 있는 방법에는 여러 가지가 있습니다.\n","\n","사용 가능한 신호로 변환하는 간단한 방법은 `sin` 및 `cos`를 사용하여 시간을 명확한 \"하루 중 시간\" 및 \"연중 시간\" 신호로 변환하는 것입니다."]},{"cell_type":"code","metadata":{"id":"MBfX6CDwax73"},"source":["day = 24*60*60\n","year = (365.2425)*day\n","\n","df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n","df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n","df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n","df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mXBbTJZfuuTC"},"source":["plt.plot(np.array(df['Day sin'])[:25])\n","plt.plot(np.array(df['Day cos'])[:25])\n","plt.xlabel('Time [h]')\n","plt.title('Time of day signal')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NQH4_JpKDKE5"},"source":["plt.plot(np.array(df['Year sin'])[:8000])\n","plt.plot(np.array(df['Year cos'])[:8000])\n","plt.xlabel('Time [h]')\n","plt.title('Time of year signal')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HiurzTGQgf_D"},"source":["그러면 모델이 가장 중요한 빈도 특성에 액세스할 수 있습니다. 이 경우 어떤 빈도가 중요한지 미리 알고 있었습니다.\n","\n","모르는 경우 `fft`를 사용하여 중요한 빈도를 결정할 수 있습니다. 시간에 따른 온도의 `tf.signal.rfft`를 보면 여기서 가정한 내용이 확인됩니다. `1/year` 및 `1/day` 근처에서 빈도 피크가 확실하다는 것을 알 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"EN4U1fcMiTYs"},"source":["fft = tf.signal.rfft(df['ta'])\n","f_per_dataset = np.arange(0, len(fft))\n","\n","n_samples_h = len(df['ta'])\n","hours_per_year = 24*365.2524\n","# hours_per_year = 24*365\n","years_per_dataset = n_samples_h/(hours_per_year)\n","\n","f_per_year = f_per_dataset/years_per_dataset\n","plt.step(f_per_year, np.abs(fft))\n","plt.xscale('log')\n","plt.ylim(0, 5e+5)\n","plt.xlim([0.1, max(plt.xlim())])\n","plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n","_ = plt.xlabel('Frequency (log scale)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_ArWmKHEkci"},"source":["df = df[['Year sin', 'Year cos', 'Day sin', 'Day cos', 'ta', 'rn', 'hm', 'pv', \n","        'td', 'pa', 'ps', 'ss', 'icsr', 'Wx', 'Wy']]\n","if True:\n","    df.drop(columns=['rn'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mY2KaQH81YsS"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2rbL8bSGDHy3"},"source":["### 데이터 분할"]},{"cell_type":"markdown","metadata":{"id":"qoFJZmXBaxCc"},"source":["훈련, 검증 및 테스트 세트에 `(70%, 20%, 10%)` 분할을 사용합니다. 분할하기 전에 데이터가 임의로 셔플되지 **않습니다**. 이것은 두 가지 이유 때문입니다.\n","\n","1. 데이터를 연속된 샘플의 창으로 자르는 것이 여전히 가능합니다.\n","2. 모델을 훈련한 후 수집된 데이터를 바탕으로 평가하므로 검증/테스트 결과가 보다 현실적입니다."]},{"cell_type":"code","metadata":{"id":"ia-MPAHxbInX"},"source":["column_indices = {name: i for i, name in enumerate(df.columns)}\n","\n","n = len(df)\n","train_df = df[0:int(n*0.7)]\n","val_df = df[int(n*0.7):int(n*0.9)]\n","test_df = df[int(n*0.9):]\n","\n","num_features = df.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1yDrHeVFFaQ0"},"source":["num_features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-eFckdUUHWmT"},"source":["### 데이터 정규화\n","\n","신경망을 훈련하기 전에 특성의 크기를 정하는 것이 중요합니다. 정규화는 이 크기 조정을 수행하는 일반적인 방법입니다. 평균을 빼고 각 특성의 표준 편차로 나눕니다."]},{"cell_type":"markdown","metadata":{"id":"mxbIic5TMlxx"},"source":["모델이 검증 및 테스트 세트의 값에 액세스할 수 없도록 훈련 데이터를 사용해서만 평균 및 표준 편차를 계산해야 합니다.\n","\n","또한 모델이 훈련할 때 훈련 세트의 미래 값에 액세스할 수 없어야 하고 이 정규화가 이동 평균을 사용하여 수행되어야 한다고 말할 수도 있습니다. 이 내용은 본 튜토리얼의 중점 사항이 아니며, 검증 및 테스트 세트가 있기 때문에 (다소) 정직한 메트릭을 얻을 수 있습니다. 따라서 단순화를 위해 이 튜토리얼에서는 단순 평균을 사용합니다."]},{"cell_type":"code","metadata":{"id":"Eji6njXvHusN"},"source":["train_mean = train_df.mean()\n","train_std = train_df.std()\n","\n","train_df = (train_df - train_mean) / train_std\n","val_df = (val_df - train_mean) / train_std\n","test_df = (test_df - train_mean) / train_std"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G6ufs8kk9JQw"},"source":["이제 특성의 분포를 살펴봅니다. 일부 특성은 꼬리가 길지만 `-9999` 풍속 값과 같은 명백한 오류는 없습니다."]},{"cell_type":"code","metadata":{"id":"T0UYEnkwm8Fe"},"source":["df_std = (df - train_mean) / train_std\n","df_std = df_std.melt(var_name='Column', value_name='Normalized')\n","plt.figure(figsize=(12, 6))\n","ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n","_ = ax.set_xticklabels(df.keys(), rotation=90)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NRw7vJzv5qEE"},"source":["####WindowGenerator"]},{"cell_type":"code","metadata":{"id":"c_pUIddaef-L"},"source":["class WindowGenerator():\n","    def __init__(self, input_width, label_width, shift,\n","                 train_df=train_df, val_df=val_df, test_df=test_df,\n","                 label_columns=None):\n","        # Store the raw data.\n","        self.train_df = train_df\n","        self.val_df = val_df\n","        self.test_df = test_df\n","\n","        # Work out the label column indices.\n","        self.label_columns = label_columns\n","        if label_columns is not None:\n","            self.label_columns_indices = {name: i for i, name in \n","                                          enumerate(label_columns)}\n","        self.column_indices = {name: i for i, name in\n","                               enumerate(train_df.columns)}\n","\n","        # Work out the window parameters.\n","        self.input_width = input_width\n","        self.label_width = label_width\n","        self.shift = shift\n","\n","        self.total_window_size = input_width + shift\n","\n","        self.input_slice = slice(0, input_width)\n","        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n","\n","        self.label_start = self.total_window_size - self.label_width\n","        self.labels_slice = slice(self.label_start, None)\n","        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n","\n","    def __repr__(self):\n","        return '\\n'.join([\n","        f'Total window size: {self.total_window_size}',\n","        f'Input indices: {self.input_indices}',\n","        f'Label indices: {self.label_indices}',\n","        f'Label column name(s): {self.label_columns}'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yVJgblsYzL1g"},"source":["이 섹션의 시작 부분에서 다이어그램에 나타낸 두 개의 창을 만드는 코드는 다음과 같습니다."]},{"cell_type":"code","metadata":{"id":"IsM5kRkz0UwK"},"source":["w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n","                     label_columns=['ta'])\n","w1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"viwKsYeAKFUn"},"source":["w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n","                     label_columns=['ta'])\n","w2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yHZ5CO2S5n9V"},"source":["####split_window"]},{"cell_type":"code","metadata":{"id":"W4KbxfzqkXPW"},"source":["def split_window(self, features):\n","  inputs = features[:, self.input_slice, :]\n","  labels = features[:, self.labels_slice, :]\n","  if self.label_columns is not None:\n","    labels = tf.stack(\n","        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n","        axis=-1)\n","\n","  # Slicing doesn't preserve static shape information, so set the shapes\n","  # manually. This way the `tf.data.Datasets` are easier to inspect.\n","  inputs.set_shape([None, self.input_width, None])\n","  labels.set_shape([None, self.label_width, None])\n","\n","  return inputs, labels\n","\n","# 클래스 정의 이후 메서드 추가\n","# https://stackoverflow.com/questions/972/adding-a-method-to-an-existing-object-instance\n","WindowGenerator.split_window = split_window"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G6U6VtVuM15s"},"source":["다음을 사용해 보세요."]},{"cell_type":"code","metadata":{"id":"YeCWbq6KLmL7"},"source":["# Stack three slices, the length of the total window:\n","example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n","                           np.array(train_df[100:100+w2.total_window_size]),\n","                           np.array(train_df[200:200+w2.total_window_size])])\n","\n","\n","example_inputs, example_labels = w2.split_window(example_window)\n","\n","print('All shapes are: (batch, time, features)')\n","print(f'Window shape: {example_window.shape}')\n","print(f'Inputs shape: {example_inputs.shape}')\n","print(f'labels shape: {example_labels.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xtMk1ffk2Mmd"},"source":["일반적으로 TensorFlow의 데이터는 가장 바깥 쪽 인덱스가 여러 예제(\"배치\" 차원)에 걸쳐 있는 배열로 구성됩니다. 중간 인덱스는 \"시간\" 또는 \"공간\"(너비, 높이) 차원입니다. 가장 안쪽 인덱스는 특성입니다.\n","\n","위의 코드는 두 배치의 7-타임스텝 창을 사용하며 각 타임스텝에는 19개의 특성이 있습니다. 그러면 이것을 한 배치의 6-타임스텝과 19개의 특성 입력 및 1-타임스텝 1-특성 레이블로 분할합니다. 레이블에는 하나의 특성만 있는데, `WindowGenerator`가 `label_columns=['T (degC)']`로 초기화되었기 때문입니다. 우선 이 튜토리얼에서는 단일 출력 레이블을 예측하는 모델을 빌드합니다."]},{"cell_type":"code","metadata":{"id":"VEPWTe14Cc45"},"source":["w2.input_slice, w2.labels_slice, w1.input_slice, w1.labels_slice"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fx2sHglV1tgt"},"source":["np.arange(w2.total_window_size)[w2.input_slice], \\\n","np.arange(w2.total_window_size)[w2.labels_slice], \\\n","np.arange(w1.total_window_size)[w1.input_slice], \\\n","np.arange(w1.total_window_size)[w1.labels_slice] "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tFZukGXrJoGo"},"source":["### 3. 플롯하기\n","\n","다음은 분할 창을 간단하게 시각화할 수 있는 플롯 메서드입니다."]},{"cell_type":"code","metadata":{"id":"fmgd1qkYUWT7"},"source":["w2.example = example_inputs, example_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jIrYccI-Hm3B"},"source":["def plot(self, model=None, plot_col='ta', max_subplots=3):\n","  inputs, labels = self.example\n","  plt.figure(figsize=(12, 8))\n","  plot_col_index = self.column_indices[plot_col]\n","  max_n = min(max_subplots, len(inputs))\n","  for n in range(max_n):\n","    plt.subplot(3, 1, n+1)\n","    plt.ylabel(f'{plot_col} [normed]')\n","    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n","             label='Inputs', marker='.', zorder=-10)\n","\n","    if self.label_columns:\n","      label_col_index = self.label_columns_indices.get(plot_col, None)\n","    else:\n","      label_col_index = plot_col_index\n","\n","    if label_col_index is None:\n","      continue\n","\n","    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n","                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n","    if model is not None:\n","      predictions = model(inputs)\n","      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n","                  marker='X', edgecolors='k', label='Predictions',\n","                  c='#ff7f0e', s=64)\n","\n","    if n == 0:\n","      plt.legend()\n","\n","  plt.xlabel('Time [h]')\n","\n","WindowGenerator.plot = plot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HXvctEuK68vX"},"source":["이 플롯은 항목이 참조하는 시간을 기준으로 입력, 레이블 및 (나중에) 예측값을 정렬합니다."]},{"cell_type":"code","metadata":{"id":"XjTqUnglOOni"},"source":["w2.plot(plot_col='pa')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UqiqcPOldPG6"},"source":["다른 열을 플롯할 수 있지만 예제 창 `w2` 구성에는 `T (degC)` 열에 대한 레이블만 있습니다."]},{"cell_type":"code","metadata":{"id":"EBRe4wnlfCH8"},"source":["w2.plot(plot_col='hm')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xCvD-UaUzYMw"},"source":["### 4. `tf.data.Dataset` 만들기"]},{"cell_type":"markdown","metadata":{"id":"kLO3SFR9Osdf"},"source":["마지막으로, 이 `make_dataset` 메서드는 시계열 `DataFrame`을 가져와 `preprocessing.timeseries_dataset_from_array` 함수를 이용해 `(input_window, label_window)` 쌍의 `tf.data.Dataset`로 변환합니다."]},{"cell_type":"markdown","metadata":{"id":"hZbwqhpfyEJ9"},"source":["#### make_dataset"]},{"cell_type":"markdown","metadata":{"id":"fREnIilVz_Il"},"source":["####tf.Dataset.map(function)"]},{"cell_type":"markdown","metadata":{"id":"iyLyZABxyIQu"},"source":["#### tf.keras.preprocessing.timeseries_dataset_from_array"]},{"cell_type":"code","metadata":{"id":"35qoSQeRVfJg"},"source":["def make_dataset(self, data):\n","  data = np.array(data, dtype=np.float32)\n","  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n","      data=data,\n","      targets=None,\n","      sequence_length=self.total_window_size,\n","      sequence_stride=1,\n","      shuffle=True,\n","      batch_size=32,)\n","\n","  ds = ds.map(self.split_window)\n","\n","  return ds\n","\n","WindowGenerator.make_dataset = make_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LvsxQwJaCift"},"source":["`WindowGenerator` 객체는 훈련, 검증 및 테스트 데이터를 보유합니다. 위의 \n","\n","---\n","\n","`make_dataset` 메서드를 사용하여 `tf.data.Datasets`로 여기에 액세스하기 위한 \n","\n","---\n","\n","특성을 추가합니다. 또한 간편한 액세스와 플롯을 위한 표준 예제 배치를 추가합니다."]},{"cell_type":"code","metadata":{"id":"VA79XecMuSXv"},"source":["data = test_df\n","ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n","    data=data,\n","    targets=None,\n","    sequence_length=w2.total_window_size,\n","    sequence_stride=1,\n","    shuffle=True,\n","    batch_size=32,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b87iJieOvRpO"},"source":["i = 0\n","for data in ds:\n","    input, target = w2.split_window(data)\n","    if not i:\n","        print(input.shape, target.shape)\n","    i += 1\n","print(f'total iteration: {i}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jZ2KkqGCfzu"},"source":["@property\n","def train(self):\n","  return self.make_dataset(self.train_df)\n","\n","@property\n","def val(self):\n","  return self.make_dataset(self.val_df)\n","\n","@property\n","def test(self):\n","  return self.make_dataset(self.test_df)\n","\n","@property\n","def example(self):\n","  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n","  result = getattr(self, '_example', None)\n","  if result is None:\n","    # No example batch was found, so get one from the `.train` dataset\n","    result = next(iter(self.train))\n","    # And cache it for next time\n","    self._example = result\n","  return result\n","\n","WindowGenerator.train = train\n","WindowGenerator.val = val\n","WindowGenerator.test = test\n","WindowGenerator.example = example"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fF_Vj6Iw3Y2w"},"source":["이제 `WindowGenerator` 객체가 `tf.data.Dataset` 객체에 대한 액세스 권한을 부여하므로 데이터를 쉽게 반복할 수 있습니다.\n","\n","`Dataset.element_spec` 속성은 데이터세트 요소의 구조, `dtypes` 및 형상을 알려줍니다."]},{"cell_type":"markdown","metadata":{"id":"zqrH0G3WzANs"},"source":["#### tf.Dataset.element_spec"]},{"cell_type":"code","metadata":{"id":"daJ0-U383YVs"},"source":["# Each element is an (inputs, label) pair\n","w2.train.element_spec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XKTx3_Z7ua-n"},"source":["`Dataset`를 반복하면 구체적인 배치가 생성됩니다."]},{"cell_type":"markdown","metadata":{"id":"VDT5h4cVzJCV"},"source":["#### tf.Dataset.take(counts)"]},{"cell_type":"code","metadata":{"id":"6gtKXEgf4Iml"},"source":["for example_inputs, example_labels in w2.train.take(1):\n","  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n","  print(f'Labels shape (batch, time, features): {example_labels.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LyuGuJUgjUK3"},"source":["## 단일 스텝 모델\n","\n","이러한 종류의 데이터를 기반으로 빌드할 수 있는 가장 간단한 모델은 현재 조건에만 기초하여 미래로 1 타임스텝(1시간) 진행된 단일 특성 값을 예측하는 모델입니다.\n","\n","따라서 1시간 미래의 `T (degC)` 값을 예측하는 모델을 빌드하는 것으로 시작하겠습니다.\n","\n","![Predict the next time step](https://www.tensorflow.org/tutorials/structured_data/images/narrow_window.png)\n","\n","다음과 같은 단일 스텝 `(input, label)` 쌍을 생성하도록 `WindowGenerator` 객체를 구성합니다."]},{"cell_type":"code","metadata":{"id":"tTHO7Unr4H2M"},"source":["single_step_window = WindowGenerator(\n","    input_width=1, label_width=1, shift=1, \n","    label_columns=['ta'])\n","single_step_window"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbaMxgdj5Yo5"},"source":["for example_inputs, example_labels in single_step_window.train.take(1):\n","    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n","    print(f'Labels shape (batch, time, features): {example_labels.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D1bbPiR3VAm_"},"source":["### 기준\n","\n","훈련 가능한 모델을 빌드하기 전에 나중에 더 복잡한 모델과 비교하기 위한 포인트로 성능 기준을 갖는 것이 좋습니다.\n","\n","첫 번째 작업은 모든 특성의 현재 값을 고려하여 1시간 미래의 온도를 예측하는 것입니다. 현재 값에는 현재 온도가 포함됩니다.\n","\n","따라서 예측으로 현재 온도를 반환하여 \"변화 없음\"을 예측하는 모델로 시작하겠습니다. 온도는 천천히 변하기 때문에 이것은 합리적인 기준입니다. 물론, 더 미래로 들어가면 이 기준의 예측 효과는 떨어질 것입니다.\n","\n","![Send the input to the output](https://www.tensorflow.org/tutorials/structured_data/images/baseline.png)"]},{"cell_type":"code","metadata":{"id":"Mm5AJW377bnX"},"source":["class Baseline(tf.keras.Model):\n","    def __init__(self, label_index=None):\n","        super().__init__()\n","        self.label_index = label_index\n","\n","    def call(self, inputs):\n","        if self.label_index is None:\n","            return inputs\n","        result = inputs[:, :, self.label_index]\n","        return result[:, :, tf.newaxis]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wMmeWCU8vKh"},"source":["baseline = Baseline(label_index=column_indices['ta'])\n","\n","baseline.compile(loss=tf.losses.MeanSquaredError(),\n","                 metrics=[tf.metrics.MeanAbsoluteError()])\n","\n","val_performance = {}\n","performance = {}\n","val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n","performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AIlnjdGaB3aD"},"source":["single_step_window.plot(baseline)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nhBxQcCSs7Ec"},"source":["몇 가지 성능 메트릭을 출력했지만 모델이 얼마나 잘 동작하는지에 대한 느낌은 주지 않습니다.\n","\n","`WindowGenerator`에는 플롯 메서드가 있지만 단일 샘플만으로는 플롯이 그다지 흥미롭지 않습니다. 따라서 한 번에 24시간 범위의 연속 입력과 레이블을 생성하는 더 넓은 `WindowGenerator`를 만듭니다.\n","\n","`wide_window`는 모델이 동작하는 방식을 변화시키지 않습니다. 이 모델은 단일 입력 타임스텝을 기반으로 1시간 미래를 예측합니다. 여기서 `time` 축은 `batch` 축과 같은 역할을 합니다. 각 예측은 타임스텝 사이의 상호 작용 없이 독립적으로 이루어집니다."]},{"cell_type":"code","metadata":{"id":"C8jNR5uuJ5Zp"},"source":["wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1,\n","    label_columns=['ta'])\n","\n","wide_window"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZAnj7CFZkuYv"},"source":["이 확장된 창은 어떠한 코드 변경 없이 동일한 `baseline` 모델에 직접 전달할 수 있습니다. 이는 입력과 레이블이 동일한 수의 타임스텝을 가지며 기준이 입력을 출력으로 전달하기 때문에 가능합니다.\n","\n","![One prediction 1h into the future, ever hour.](https://www.tensorflow.org/tutorials/structured_data/images/last_window.png)"]},{"cell_type":"code","metadata":{"id":"sGKdvdg087qs"},"source":["print('Input shape:', single_step_window.example[0].shape)\n","print('Output shape:', baseline(single_step_window.example[0]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ueY4VYaBxR4"},"source":["print('Input shape:', wide_window.example[0].shape)\n","print('Output shape:', baseline(wide_window.example[0]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SKqQHX1K0JW-"},"source":["기준 모델의 예측값을 플롯하면 1시간씩 오른쪽으로 이동한 단순한 레이블임을 알 수 있습니다."]},{"cell_type":"code","metadata":{"id":"jQyAPVLgWTOZ"},"source":["wide_window.plot(baseline)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e93TLUhfAVg2"},"source":["위의 세 가지 예제 플롯에서 단일 스텝 모델은 24시간 동안 실행됩니다. 이에 관해 몇 가지 설명이 필요합니다.\n","\n","- 파란색 \"입력\" 라인은 각 타임스텝의 입력 온도를 보여줍니다. 이 모델은 모든 특성을 수신하며 이 플롯은 온도만 표시합니다.\n","- 녹색 \"레이블\" 점은 목표 예측값을 나타냅니다. 이러한 점은 입력 시간이 아니라 예측 시간에 표시됩니다. 레이블의 범위가 입력에 상대적으로 한 스텝 이동하는 이유가 여기에 있습니다.\n","- 주황색 \"예측\" 십자는 각 출력 타임스텝에 대한 모델의 예측입니다. 모델이 완벽하게 예측하는 경우 예측값은 \"레이블\" 바로 위에 놓여집니다."]},{"cell_type":"markdown","metadata":{"id":"E4aOJScj52Yu"},"source":["### 선형 모델\n","\n","이 작업에 적용할 수 있는 가장 간단한 **훈련 가능한** 모델은 입력과 출력 사이에 선형 변환을 삽입하는 것입니다. 이 경우 타임스텝의 출력은 해당 스텝에만 의존합니다.\n","\n","![A single step prediction](https://www.tensorflow.org/tutorials/structured_data/images/narrow_window.png)\n","\n","`activation` 세트가 없는 `layers.Dense`는 선형 모델입니다. 레이어는 데이터의 마지막 축을 `(batch, time, inputs)`에서 `(batch, time, units)`로만 변환하며, `batch` 및 `time` 축의 모든 항목에 독립적으로 적용됩니다."]},{"cell_type":"code","metadata":{"id":"0ivbKG6C9oIO"},"source":["linear = tf.keras.Sequential([\n","                              tf.keras.layers.Dense(units=1)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9BIr_Pr9vuo"},"source":["print('Input shape:', single_step_window.example[0].shape)\n","print('Output shape:', linear(single_step_window.example[0]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ql9HPNKljj8W"},"source":["# Saving layer weights at each epoch\n","# https://stackoverflow.com/questions/44938160/saving-layer-weights-at-each-epoch-during-training-into-a-numpy-type-array-conv\n","class CustomCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        logs = logs or {}\n","        self.epoch.append(epoch)\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n","\n","        modelWeights = []\n","        for layer in model.layers:\n","            layerWeights = []\n","            for weight in layer.get_weights():\n","                layerWeights.append(weight)\n","            modelWeights.append(layerWeights)\n","        self.weights.append(modelWeights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bQVXD5zmldT"},"source":["weight_list = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cc9888d28e79"},"source":["class CustomCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, model):\n","        self.model = model\n","        \n","    def on_epoch_end(self, epoch, logs=None):\n","        epoch_weight = self.model.layers[0].kernel[:, 0].numpy()\n","        weight_list.append(epoch_weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1UmASQSFaZL"},"source":["MAX_EPOCHS = 20\n","def compile_and_fit(model, window, patience=2):\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                      patience=patience,\n","                                                      mode='min')\n","    model.compile(loss=tf.losses.MeanSquaredError(),\n","                  optimizer=tf.optimizers.Adam(),\n","                  metrics=[tf.metrics.MeanAbsoluteError()])\n","    history = model.fit(window.train, epochs=MAX_EPOCHS,\n","                        validation_data=window.val,\n","                        callbacks=[early_stopping,\n","                                #    CustomCallback(model),\n","                                   ])\n","    return history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4IIts7qH1Y4"},"source":["history = compile_and_fit(linear, single_step_window)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFtt0lTAr7Gs"},"source":["# CustomCallback 호출시에 저장된 가중치의 변화 그래프를 출력\n","if False:\n","    df = pd.DataFrame(_weights)\n","    _weights = np.array(weight_list)\n","    df.plot()\n","    plt.legend(train_df.columns, )\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYpLtm98ILNg"},"source":["val_performance['Linear'] = linear.evaluate(single_step_window.val, verbose=2)\n","performance['Linear'] = linear.evaluate(single_step_window.test, verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7U9XukYh8beN"},"source":["`baseline` 모델과 마찬가지로 선형 모델은 넓은 범위의 배치에서 호출할 수 있습니다. 이러한 방식으로 모델은 연속적인 타임스텝에 대해 일련의 독립적인 예측을 수행합니다. `time` 축은 다른 `batch` 축처럼 작동합니다. 각 타임스텝에서 예측 사이에 상호 작용은 없습니다.\n","\n","![A single step prediction](https://www.tensorflow.org/tutorials/structured_data/images/wide_window.png)"]},{"cell_type":"code","metadata":{"id":"wLZoQvQIOXvS"},"source":["print('Input shape:', wide_window.example[0].shape)\n","print('Output shape:', baseline(wide_window.example[0]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWK33xATOmxc"},"source":["wide_window.plot(linear)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-PnHSS8ZOxrL"},"source":["# baseline model evaluation\n","loss, mae = baseline.evaluate(wide_window.test)\n","# linear model evaluation\n","loss, mae = linear.evaluate(wide_window.test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BwqHZ7xEf4Xd"},"source":["#### tf.keras.Model.`layers.kernel`"]},{"cell_type":"code","metadata":{"id":"9k0mCwUQPw4s"},"source":["bar_y = linear.layers[0].kernel[:, 0].numpy()\n","bar_x = range(len(train_df.columns))\n","plt.bar(x=bar_x, height=bar_y)\n","axis = plt.gca()\n","axis.set_xticks(bar_x)  \n","_ = axis.set_xticklabels(train_df.columns, rotation=90)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ylng7215boIY"},"source":["때로 모델은 입력 `T (degC)`에 가장 많은 가중치를 두지 않습니다. 이것은 무작위 초기화의 위험 중 하나입니다. "]},{"cell_type":"markdown","metadata":{"id":"W18e6da1cNbw"},"source":["### 밀집\n","\n","실제로 여러 타임스텝에서 동작하는 모델을 적용하기 전에 더 깊고 강력한 단일 입력 스텝 모델의 성능을 확인하는 것이 좋습니다.\n","\n","다음 모델은 입력과 출력 사이에 몇 개의 `Dense` 레이어를 쌓는다는 점을 제외하면 `linear` 모델과 유사합니다. "]},{"cell_type":"code","metadata":{"id":"hpsrS3B6iUfc"},"source":["dense = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=1)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fMk7JFfinxA"},"source":["history = compile_and_fit(dense, single_step_window)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eSRGQHei40D"},"source":["val_performance['Dense'] = dense.evaluate(single_step_window.val)\n","performance['Dense'] = dense.evaluate(single_step_window.test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQE3IUXSlfTg"},"source":["pd.DataFrame(performance).plot()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j5dv_whJdswH"},"source":["### 다중 스텝 밀집\n","\n","단일 타임스텝 모델에는 입력의 현재 값에 대한 컨텍스트가 없습니다. 시간에 따라 입력 특성이 어떻게 변하는지 볼 수 없습니다. 이 문제를 해결하려면 모델이 예측을 수행할 때 여러 타임스텝에 액세스해야 합니다.\n","\n","![Three time steps are used for each prediction.](https://www.tensorflow.org/tutorials/structured_data/images/conv_window.png)\n"]},{"cell_type":"markdown","metadata":{"id":"Zac-ti8agbJ7"},"source":["`baseline` , `linear` 및 `dense` 모델은 각 타임스텝을 독립적으로 처리했습니다. 여기서 모델은 단일 출력을 생성하기 위해 여러 타임스텝을 입력으로 사용합니다.\n","\n","3시간의 입력과 1시간의 레이블 배치를 생성하는 `WindowGenerator`를 만듭니다."]},{"cell_type":"markdown","metadata":{"id":"gtN4BwZ37niR"},"source":["`Window`의 `shift` 매개변수는 두 창의 끝에 상대적입니다.\n"]},{"cell_type":"code","metadata":{"id":"JPANyXDYmLrz"},"source":["CONV_WIDTH = 3\n","conv_window = WindowGenerator(\n","    input_width=CONV_WIDTH,\n","    label_width=1,\n","    shift=1,\n","    label_columns=['ta']\n",")\n","\n","conv_window"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hDISpwjLmYPO"},"source":["conv_window.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"We0HdMxKeqB_"},"source":["`layers.Flatten`을 모델의 첫 번째 레이어로 추가하여 다중 입력 스텝 창에서 `dense` 모델을 훈련할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"J_CGAmT65R5K"},"source":["multi_step_dense = tf.keras.Sequential([\n","    # Shape: (time, features) => (time*features)\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(1),\n","    # Add back the time dimension.\n","    # Shape: (outputs) => (1, outputs)\n","    tf.keras.layers.Reshape([-1, 1])\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDkWTozu7Ff_"},"source":["def print_shape(self, model):\n","    print('Input shape:', self.example[0].shape)\n","    print('Output shape:', model(self.example[0]).shape)\n","    \n","WindowGenerator.print_shape = print_shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4jbGg608Aw1"},"source":["history = compile_and_fit(window=conv_window, model=multi_step_dense)\n","IPython.display.clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QQmVmD58K14"},"source":["val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n","performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"In03tbcu8-wN"},"source":["conv_window.plot(multi_step_dense)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrpU6gwSJome"},"source":["### 컨볼루션 신경망\n","\n","컨볼루션 레이어(`layers.Conv1D`)도 각 예측에 대한 입력으로 여러 타임스텝을 사용합니다."]},{"cell_type":"markdown","metadata":{"id":"cdLBwoaHmsWb"},"source":["다음은 컨볼루션으로 다시 작성한 `multi_step_dense`와 **동일한** 모델입니다.\n","\n","다음 변경 사항에 주목하세요.\n","\n","- `layers.Flatten`과 첫 번째 `layers.Dense`는 `layers.Conv1D`로 대체됩니다.\n","- 컨볼루션이 출력에서 시간 축을 유지하므로 `layers.Reshape`는 이 더 이상 필요하지 않습니다."]},{"cell_type":"code","metadata":{"id":"m1ayN70rQc2I"},"source":["conv_model = tf.keras.Sequential(\n","    name='conv_model',\n","    layers=[\n","           tf.keras.layers.Conv1D(filters=32,\n","                                  kernel_size=(CONV_WIDTH),\n","                                  activation='relu'),\n","           tf.keras.layers.Dense(units=32, activation='relu'),\n","           tf.keras.layers.Dense(units=1),\n","    ]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8olKxfsIRLBo"},"source":["conv_window.print_shape(conv_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6EtUATC3Rb1f"},"source":["history = compile_and_fit(model=conv_model, window=conv_window)\n","IPython.display.clear_output()\n","\n","val_performance['Conv'] = conv_model.evaluate(conv_window.val)\n","performance['Conv'] = conv_model.evaluate(conv_window.test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zTY8yzJmTE8v"},"source":["pd.DataFrame(val_performance).plot()\n","pd.DataFrame(performance).plot()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sYRipDeXs0Kr"},"source":["이 `conv_model`과 `multi_step_dense` 모델의 차이점은 `conv_model`은 모든 길이의 입력에서 실행될 수 있다는 것입니다. 컨볼루셔널 레이어는 입력의 슬라이딩 윈도우에 적용됩니다.\n","\n","![Executing a convolutional model on a sequence](https://www.tensorflow.org/tutorials/structured_data/images/wide_conv_window.png)\n","\n","더 넓은 입력에서 실행하면 더 넓은 출력이 생성됩니다."]},{"cell_type":"code","metadata":{"id":"hoqccxx9r5jF"},"source":["print(\"Wide window\")\n","print('Input shape:', wide_window.example[0].shape)\n","print('Labels shape:', wide_window.example[1].shape)\n","print('Output shape:', conv_model(wide_window.example[0]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmOTYsOdVnhM"},"source":["# Conv1D test cell\n","sample_X = np.array([0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=np.float32)\n","sample_X = sample_X.reshape(1, len(sample_X), 1)\n","model = tf.keras.Sequential([tf.keras.layers.Conv1D(1, 3)])\n","print(model(sample_X))\n","model.layers[0].kernel.numpy().flatten()#.sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h_WGxtLIHhRF"},"source":["출력은 입력보다 짧습니다. 훈련 또는 플롯 작업을 수행하려면 레이블과 예상의 길이가 동일해야 합니다. 따라서 레이블과 예측 길이가 일치하도록 몇 개의 추가 입력 타임스텝으로 넓은 창을 생성하는 `WindowGenerator`를 빌드합니다. "]},{"cell_type":"code","metadata":{"id":"_VPvJ_VwTc0f"},"source":["LABEL_WIDTH = 24\n","INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n","wide_conv_window = WindowGenerator(\n","    input_width=INPUT_WIDTH,\n","    label_width=LABEL_WIDTH,\n","    shift=1,\n","    label_columns=['ta'])\n","\n","wide_conv_window"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtqlWYXeKXej"},"source":["print(\"Wide conv window\")\n","print('Input shape:', wide_conv_window.example[0].shape)\n","print('Labels shape:', wide_conv_window.example[1].shape)\n","print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yzxbbS56cSBV"},"source":["이제 더 넓은 창에 모델의 예측값을 플롯할 수 있습니다. 첫 번째 예측 전 3개의 입력 타임스텝에 주목하세요. 여기서 모든 예측은 이전 3개의 타임스텝에 기초합니다."]},{"cell_type":"code","metadata":{"id":"gR7VyL45UuEe"},"source":["wide_conv_window.plot(conv_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H4crpOcoMlSe"},"source":["### 순환 신경망\n","\n","Recurrent Neural Network(RNN)는 시계열 데이터에 적합한 신경망 유형입니다. RNN은 시계열을 단계별로 처리하여 타임스텝 사이에서 내부 상태를 유지합니다.\n","\n","자세한 내용은 [텍스트 생성 튜토리얼](https://www.tensorflow.org/tutorials/text/text_generation) 또는 [RNN 가이드](https://www.tensorflow.org/guide/keras/rnn)를 읽어보세요.\n","\n","이 튜토리얼에서는 [Long Short Term Memory](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM)(LSTM)이라는 RNN 레이어를 사용합니다."]},{"cell_type":"markdown","metadata":{"id":"vfQbHSMb1ATa"},"source":["모든 keras RNN 레이어에 대한 중요한 생성자 인수는 `return_sequences` 인수입니다. 이 설정은 다음 두 가지 방법 중 하나로 레이어를 구성할 수 있습니다.\n","\n","1. 기본값인 `False`인 경우 레이어는 최종 타임스텝의 출력만 반환하여 단일 예측을 수행하기 전에 모델이 내부 상태를 준비할 시간을 줍니다.\n","\n","![An lstm warming up and making a single prediction](https://www.tensorflow.org/tutorials/structured_data/images/lstm_1_window.png)\n","\n","1. `True`이면 레이어가 각 입력에 대한 출력을 반환합니다. 다음과 같은 경우에 유용합니다.\n","\n","- RNN 레이어 쌓기\n","- 여러 타임스텝에서 동시에 모델 훈련\n","\n","![An lstm making a prediction after every timestep](https://www.tensorflow.org/tutorials/structured_data/images/lstm_many_window.png)"]},{"cell_type":"code","metadata":{"id":"0trGLKobhoCw"},"source":["lstm_model = tf.keras.Sequential(\n","    name='lstm_model',\n","    layers=[\n","            # Shape [batch, time, features] => [batch, time, lstm_units]\n","            tf.keras.layers.LSTM(32, return_sequences=True),\n","            # Shape => [batch, time, feautres]\n","            tf.keras.layers.Dense(1)\n","    ]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F124B00KZcLC"},"source":["`return_sequences=True`이면 모델을 한 번에 24시간 분량 데이터에 대해 훈련할 수 있습니다.\n","\n","참고: 이 경우에는 모델 성능의 관점에서 기대할 것이 없습니다. 첫 번째 타임스텝에서 모델이 이전 스텝에 액세스할 수 없으므로 이전에 표시한 단순한 `linear` 및 `dense` 모델보다 더 나을 것이 없기 때문입니다."]},{"cell_type":"code","metadata":{"id":"HFoiFDPWmuib"},"source":["wide_window.print_shape(lstm_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGavSqMZwKeF"},"source":["# LSTM example\n","for input, target in wide_window.train.take(1):\n","    output = tf.keras.layers.LSTM(32, return_sequences=True)(input)\n","    print(output.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nwEgON9xVMC"},"source":["lstm_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3womxfUm7x1"},"source":["history = compile_and_fit(model=lstm_model, window=wide_window)\n","IPython.display.clear_output()\n","\n","val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n","performance['LSTM'] = lstm_model.evaluate(wide_window.test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vyZ9f8pknODo"},"source":["wide_window.plot(lstm_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pYglOCKehi8F"},"source":["### 성능"]},{"cell_type":"markdown","metadata":{"id":"2pCk0_rwhi8H"},"source":["이 데이터세트를 사용하면 일반적으로 각 모델의 성능이 이전 모델보다 약간 더 좋습니다."]},{"cell_type":"code","metadata":{"id":"chkY1ebpu5gU"},"source":["single_val_performance = val_performance\n","single_performance = performance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JjEkt488hi8I"},"source":["x = np.arange(len(single_performance))\n","width = 0.3\n","metric_name = 'mean_absolute_error'\n","metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n","val_mae = [v[metric_index] for v in single_val_performance.values()]\n","test_mae = [v[metric_index] for v in single_performance.values()]\n","\n","plt.ylabel('mean_absolute_error [T (degC), normalized]')\n","plt.bar(x - 0.17, val_mae, width, label='Validation')\n","plt.bar(x + 0.17, test_mae, width, label='Test')\n","plt.xticks(ticks=x, labels=single_performance.keys(),\n","           rotation=45)\n","_ = plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBMCpsdphi8L"},"source":["for name, value in performance.items():\n","  print(f'{name:12s}: {value[1]:0.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5rUJ_2YMWzG"},"source":["### 다중 출력 모델\n","\n","지금까지 모델은 모두 단일 타임스텝에 대해 단일 출력 특성 `T (degC)`를 예측했습니다.\n","\n","이러한 모든 모델은 간단히 출력 레이어의 단위 수를 변경하고 `labels`에 모든 특성을 포함하도록 훈련 창을 조정하여 여러 특성을 예측하도록 변환할 수 있습니다.\n"]},{"cell_type":"code","metadata":{"id":"LR-7VODznVBh"},"source":["single_step_window = WindowGenerator(\n","    # `WindowGenerator` returns all features as labels if you\n","    # dont't set the `label_columns` argument.\n","    input_width =1, label_width=1, shift=1\n",")\n","wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1\n",")\n","\n","for example_inputs, example_labels in wide_window.train.take(1):\n","    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n","    print(f'Labels shape (batch, time, features): {example_labels.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XmcjHfDskX1N"},"source":["레이블의 `features` 축은 이제 1이 아닌 입력과 동일한 깊이를 갖습니다."]},{"cell_type":"markdown","metadata":{"id":"9k7S5IHNhSNF"},"source":["#### 기준\n","\n","여기서는 동일한 기준 모델을 사용할 수 있지만 이번에는 특정 `label_index`를 선택하는 대신 모든 특성을 반복합니다."]},{"cell_type":"code","metadata":{"id":"DJjO786fqYd4"},"source":["baseline = Baseline()\n","baseline.compile(loss=tf.losses.MeanSquaredError(),\n","                 metrics=[tf.metrics.MeanAbsoluteError()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0ScMq8cvYVd"},"source":["val_performance = {}\n","performance = {}\n","val_performance['Baseline'] = baseline.evaluate(wide_window.val)\n","performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dfbCrf5q3P6n"},"source":["#### 밀집"]},{"cell_type":"code","metadata":{"id":"ILuTWokLvju6"},"source":["dense = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=num_features)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJDMuagoTKTs"},"source":["history = compile_and_fit(dense, single_step_window)\n","\n","IPython.display.clear_output()\n","val_performance['Dense'] = dense.evaluate(single_step_window.val)\n","performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dsc9pur_mHsx"},"source":["#### RNN\n"]},{"cell_type":"code","metadata":{"id":"mi13UjHWLQjs"},"source":["%%time\n","wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1)\n","\n","lstm_model = tf.keras.models.Sequential([\n","    # Shape [batch, time, features] => [batch, time, lstm_units]\n","    tf.keras.layers.LSTM(32, return_sequences=True), #[]\n","    # Shape => [batch, time, features]\n","    tf.keras.layers.Dense(units=num_features)\n","])\n","\n","history = compile_and_fit(lstm_model, wide_window)\n","\n","IPython.display.clear_output()\n","val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n","performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n","\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3PRF0QFXSLN"},"source":["lstm_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtSZucxovl1Y"},"source":["for sample in wide_window.train.take(1):\n","    input, target = sample\n","    output = tf.keras.layers.LSTM(32, return_sequences=True)(input)\n","    output_f = tf.keras.layers.LSTM(32, return_sequences=False)(input)\n","    print(output.numpy()[0,:,0])\n","    print(output_f.numpy()[0, :])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZiHK6RtWveSF"},"source":["wide_window.print_shape(lstm_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwhY2f_Nn0_K"},"source":["<a id=\"residual\"></a>\n","\n","#### 고급: 잔여 연결\n","\n","이전의 `Baseline` 모델은 시퀀스가 타임스텝 사이에서 크게 변하지 않는다는 사실을 이용했습니다. 지금까지 이 튜토리얼에서 훈련한 모든 모델은 무작위로 초기화된 다음, 출력이 이전 타임스텝에서 약간 변경된다는 사실을 학습해야 했습니다.\n","\n","신중한 초기화로 이 문제를 해결할 수 있지만 모델 구조로 빌드하는 것이 더 간단합니다.\n","\n","시계열 분석에서는 다음 값을 예측하는 대신 다음 타임스텝에서 값이 어떻게 달라지는 지를 예측하는 모델을 빌드하는 것이 일반적입니다. 마찬가지로 딥러닝에서 \"잔여 네트워크(Residual networks)\" 또는 \"ResNets\"는 각 레이어가 모델의 누적 결과에 추가되는 아키텍처를 나타냅니다.\n","\n","이것은 변화가 작아야 한다는 사실을 이용하는 방법입니다.\n","\n","![A model with a residual connection](https://www.tensorflow.org/tutorials/structured_data/images/residual.png)\n","\n","기본적으로, `Baseline`과 일치하도록 모델을 초기화합니다. 그러면 이 작업에서 약간 더 나은 성능으로 모델이 더 빨리 수렴하는 데 도움이 됩니다."]},{"cell_type":"markdown","metadata":{"id":"yP58A_ORx0kM"},"source":["이 접근 방식은 이 튜토리얼에서 설명하는 모든 모델과 연계하여 사용할 수 있습니다.\n","\n","여기서는 LSTM 모델에 적용합니다. `tf.initializers.zeros`를 사용하여 초기 예측하는 변경이 작고 잔류 연결을 억제하지 않도록 한다는 점에 주목하세요. `zeros`가 마지막 레이어에서만 사용되기 때문에 여기에서 그래디언트에 대한 대칭성이 깨질 우려는 없습니다."]},{"cell_type":"code","metadata":{"id":"7YlfnDQC22TQ"},"source":["class ResidualWrapper(tf.keras.Model):\n","  def __init__(self, model):\n","    super().__init__()\n","    self.model = model\n","\n","  def call(self, inputs, *args, **kwargs):\n","    delta = self.model(inputs, *args, **kwargs)\n","\n","    # The prediction for each timestep is the input\n","    # from the previous time step plus the delta\n","    # calculated by the model.\n","    return inputs + delta"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNeH02pspc9B"},"source":["%%time\n","residual_lstm = ResidualWrapper(\n","    tf.keras.Sequential([\n","    tf.keras.layers.LSTM(32, return_sequences=True),\n","    tf.keras.layers.Dense(\n","        num_features,\n","        # The predicted deltas should start small\n","        # So initialize the output layer with zeros\n","        kernel_initializer=tf.initializers.zeros)\n","]))\n","\n","history = compile_and_fit(residual_lstm, wide_window)\n","\n","IPython.display.clear_output()\n","val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n","performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I42Er9Du6co1"},"source":["#### 성능"]},{"cell_type":"markdown","metadata":{"id":"LZxR38P_6pUi"},"source":["다음은 이러한 다중 출력 모델의 전반적인 성능입니다."]},{"cell_type":"code","metadata":{"id":"6XgTK9tnr7rc"},"source":["x = np.arange(len(performance))\n","width = 0.3\n","\n","metric_name = 'mean_absolute_error'\n","metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n","val_mae = [v[metric_index] for v in val_performance.values()]\n","test_mae = [v[metric_index] for v in performance.values()]\n","\n","plt.bar(x - 0.17, val_mae, width, label='Validation')\n","plt.bar(x + 0.17, test_mae, width, label='Test')\n","plt.xticks(ticks=x, labels=performance.keys(),\n","           rotation=45)\n","plt.ylabel('MAE (average over all outputs)')\n","_ = plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"URz3ajCc6kBj"},"source":["for name, value in performance.items():\n","  print(f'{name:15s}: {value[1]:0.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Vt2MJhNxwPU"},"source":["위의 성능은 모든 모델 출력에 대한 평균입니다."]},{"cell_type":"markdown","metadata":{"id":"eYokb7Om2YbK"},"source":["## 다중 스텝 모델\n","\n","이전 섹션의 단일 출력 및 다중 출력 모델은 모두 미래 1시간의 **단일 타임스텝 예측**을 수행했습니다.\n","\n","이 섹션에서는 이러한 모델을 확장하여 **다중 타임스텝 예측**을 수행하는 방법을 살펴봅니다.\n","\n","다중 스텝 예측에서 모델은 일정 범위의 미래 값을 예측하는 방법을 학습해야 합니다. 따라서 한 미래 시점만 예측하는 단일 스텝 모델과 달리 다중 스텝 모델은 미래 값의 시퀀스를 예측합니다.\n","\n","대략적으로 두 가지 접근 방식이 있습니다.\n","\n","1. 전체 시계열이 한 번에 예측되는 싱글샷 예측\n","2. 모델이 단일 스텝 예측만 수행하고 출력이 입력으로 피드백되는 자기 회귀적 예측\n","\n","이 섹션에서는 모든 모델이 **모든 출력 타임스텝에 걸쳐 모든 특성**을 예측합니다.\n"]},{"cell_type":"markdown","metadata":{"id":"WFsDAwVt4_rq"},"source":["다중 스텝 모델의 경우, 훈련 데이터는 다시 시간별 샘플로 구성됩니다. 그러나 여기에서 모델은 과거의 24시간을 고려하여 미래 24시간을 예측하는 방법을 학습합니다.\n","\n","다음은 데이터세트로부터 이러한 조각을 생성하는 `Window` 객체입니다."]},{"cell_type":"code","metadata":{"id":"dbQaNY9Ay7Wr"},"source":["OUT_STEPS = 24\n","multi_window = WindowGenerator(input_width=24,\n","                               label_width=OUT_STEPS,\n","                               shift=OUT_STEPS)\n","multi_window.plot()\n","multi_window"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5lg8SInh9Jzd"},"source":["### 기준"]},{"cell_type":"markdown","metadata":{"id":"axwpoWYOApJL"},"source":["이 작업의 간단한 기준은 필요한 출력 타임스텝 수에 대해 마지막 입력 타임스텝을 반복하는 것입니다.\n","\n","![Repeat the last input, for each output step](https://www.tensorflow.org/tutorials/structured_data/images/multistep_last.png)"]},{"cell_type":"code","metadata":{"id":"RogvjgWm8fxu"},"source":["class MultiStepLastBaseline(tf.keras.Model):\n","    def call(self, inputs):\n","        return tf.tile(inputs[:,-1,:], [1, OUT_STEPS, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5dk7en71-3mw"},"source":["last_baseline = MultiStepLastBaseline()\n","last_baseline.compile(loss=tf.losses.MeanSquaredError(),\n","                      metrics=[tf.metrics.MeanAbsoluteError()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MvZtD2Z5_QF1"},"source":["multi_val_performance = {}\n","multi_performance = {}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PxArpeVASlv"},"source":["for batch in multi_window.val.take(1):\n","    inputs, target = batch\n","    outputs = last_baseline(inputs)\n","    print(outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNXeqvf1AOW0"},"source":["tf.tile(inputs[:,-1:,:], [1, OUT_STEPS, 1], )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRbOW3uA_XGp"},"source":["multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n","multi_performance['Last'] = last_baseline.evaluate(multi_window.val)\n","multi_window.plot(last_baseline)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8Y1uMhGwIRs"},"source":["class RepeatBaseline(tf.keras.Model):\n","  def call(self, inputs):\n","    return inputs\n","\n","repeat_baseline = RepeatBaseline()\n","repeat_baseline.compile(loss=tf.losses.MeanSquaredError(),\n","                        metrics=[tf.metrics.MeanAbsoluteError()])\n","\n","multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n","multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n","multi_window.plot(repeat_baseline)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tbndS-ct9C2Q"},"source":["### 싱글샷 모델\n","\n","이 문제에 대한 한 가지 높은 수준의 접근 방법은 모델이 한 번에 전체 시퀀스 예측을 수행하는 \"싱글샷\" 모델을 사용하는 것입니다.\n","\n","이 모델은 `OUT_STEPS*features` 출력 단위를 이용해 `layers.Dense`로 효율적으로 구현할 수 있습니다. 이 모델은 이 출력의 형상을 필요한 `(OUTPUT_STEPS, features)`로 바꾸기만 하면 됩니다."]},{"cell_type":"markdown","metadata":{"id":"NCKS4m1VKrDQ"},"source":["#### 선형\n","\n","마지막 입력 타임스텝을 기반으로 하는 단순한 선형 모델은 기준 모델보다 성능이 더 좋지만 강력하지 못합니다. 이 모델은 선형 프로젝션을 이용해 단일 입력 타임스텝으로부터 `OUTPUT_STEPS` 타임스텝을 예측해야 합니다. 주로 하루 중 시간과 연중 시간을 기반으로 하는 행동의 저차원 조각만 캡처할 수 있습니다.\n","\n","![Predct all timesteps from the last time-step](https://www.tensorflow.org/tutorials/structured_data/images/multistep_dense.png)"]},{"cell_type":"code","metadata":{"id":"gTixkkDTJ9Ua"},"source":["multi_linear_model = tf.keras.Sequential([\n","    # Take the last time-step.\n","    # Shape [batch, time, features] => [batch, 1, features]\n","    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n","    # Shape => [batch, 1, out_steps * features]\n","    tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                          kernel_initializer=tf.initializers.zeros),\n","    # Shape => [batch, out_steps, features]\n","    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3zdwaMCPVcA"},"source":["multi_window"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1j6jrGrIPP16"},"source":["history = compile_and_fit(multi_linear_model, multi_window)\n","IPython.display.clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6M6SMJ-tPXAR"},"source":["multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n","multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nasj29EmPXOZ"},"source":["multi_window.plot(multi_linear_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6mS1YN-GTlA9"},"source":["multi_dense_model = tf.keras.Sequential(\n","    [tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n","     tf.keras.layers.Dense(512, activation='relu'),\n","     tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                           kernel_initializer=tf.initializers.zeros),\n","     tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1DxBVp1ULqn"},"source":["history = compile_and_fit(multi_dense_model, multi_window)\n","IPython.display.clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k5brJSlbURoL"},"source":["multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n","multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test)\n","multi_window.plot(multi_dense_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"icsBAjCzMaMl"},"source":["#### CNN"]},{"cell_type":"markdown","metadata":{"id":"34lCZrWYNBwd"},"source":["컨볼루션 모델은 고정 너비 기록을 기반으로 예측을 수행하므로 시간에 따라 상황이 어떻게 변하는지 볼 수 있어 밀집 모델보다 성능을 높일 수 있습니다.\n","\n","![A convolutional model sees how things change over time](https://www.tensorflow.org/tutorials/structured_data/images/multistep_conv.png)"]},{"cell_type":"code","metadata":{"id":"nhSZTLkSUffP"},"source":["CONV_WIDTH = 3\n","multi_conv_model = tf.keras.Sequential([\n","    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n","    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n","    # Shape => [batch, 1, conv_units]\n","    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n","    # Shape => [batch, 1, out_steps*features]\n","    tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                          kernel_initializer=tf.initializers.zeros),\n","    # Shape => [batch, out_steps, features]\n","    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_G_8SBB5-GhH"},"source":["history = compile_and_fit(multi_conv_model, multi_window)\n","IPython.display.clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o9wPXEUI-SyQ"},"source":["multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n","multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"weBjeZAFJOP4"},"source":["#### RNN"]},{"cell_type":"markdown","metadata":{"id":"8022xOKxOO92"},"source":["반복 모델은 모델이 수행하는 예측과 관련이 있는 경우 긴 입력 기록을 사용하는 방법을 학습할 수 있습니다. 여기서 모델은 다음 24시간에 대한 단일 예측을 수행하기 전에 24시간 동안 내부 상태를 축적합니다.\n","\n","이 싱글샷 형식에서 LSTM은 마지막 타임스텝에서만 출력을 생성하면 되므로 `return_sequences=False`를 설정합니다.\n","\n","![The lstm accumulates state over the input window, and makes a single prediction for the next 24h](https://www.tensorflow.org/tutorials/structured_data/images/multistep_lstm.png)\n"]},{"cell_type":"code","metadata":{"id":"U2l0vH3O_L-1"},"source":["multi_lstm_model = tf.keras.Sequential([\n","    # Shape [batch, time, features] => [batch, lstm_untis]\n","    # Adding more `lstm_units` just overfits more quickly\n","    tf.keras.layers.LSTM(32, return_sequences=False)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XjHkrUIk_Nik"},"source":["for batch in multi_window.val.take(1):\n","    inputs, targets = batch\n","    print(f'Inputs.shape: {inputs.shape}    # [batch, time, features]')\n","    lstm = tf.keras.layers.LSTM(32, return_sequences=False)\n","    outputs = lstm(inputs)\n","    print(f'LSTM.shape: {outputs.shape}     # [batch, lstm_units]')\n","    dense = tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                          kernel_initializer=tf.initializers.zeros)\n","    outputs = dense(outputs)\n","    print(f'Dense.shape: {outputs.shape}    # [batch, out_steps*features]')\n","    reshape = tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","    outputs = reshape(outputs)\n","    print(f'Reshape.shape: {outputs.shape}  # [batch, out_steps, features]')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7iVo6C5BXzC"},"source":["multi_lstm_model = tf.keras.Sequential([\n","    # Shape [batch, time, features] => [batch, lstm_units]\n","    # Adding more `lstm_units` just overfits more quickly.\n","    tf.keras.layers.LSTM(32, return_sequences=False),\n","    # Shape => [batch, out_steps*features]\n","    tf.keras.layers.Dense(OUT_STEPS*num_features,\n","                          kernel_initializer=tf.initializers.zeros),\n","    # Shape => [batch, out_steps, features]\n","    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","])\n","\n","history = compile_and_fit(multi_lstm_model, multi_window)\n","\n","IPython.display.clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkrujCT26bRw"},"source":["# multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n","# multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n","multi_window.plot(multi_lstm_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZYzWv7HGsX1"},"source":["multi_lstm_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_oB3jd9KwJS"},"source":["(14+32+1) * 32 * 4 # lstm Param #"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jlvdcvkGw5A"},"source":["for weights in multi_lstm_model.layers[0].weights:\n","    print(weights.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_NKeWWPLD8Z"},"source":["# LSTM example\n","inputs = tf.random.normal([32, 10, 8])\n","lstm = tf.keras.layers.LSTM(4)\n","output = lstm(inputs)\n","print(output.shape)\n","\n","lstm = tf.keras.layers.LSTM(4, return_sequences=False, return_state=True)\n","whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n","print(whole_seq_output.shape)\n","print(final_memory_state.shape)\n","print(final_carry_state.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bmu0xFCKZzin"},"source":["for weights in lstm.weights:\n","    print(weights.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uVYn8SXxLUTG"},"source":["a = [1, 2, 3]\n","id(a[0]) - id(a[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d5n-1cDW12Vo"},"source":["### 고급: 자기 회귀 모델\n","\n","위의 모델은 모두 한 번에 전체 출력 시퀀스를 예측합니다.\n","\n","경우에 따라 모델이 이 예측을 여러 타임스텝으로 분해하는 것이 도움이 될 수 있습니다. 그러면 이전의 [RNN(Recurrent Neural Networks)을 이용한 시퀀스 생성](https://arxiv.org/abs/1308.0850)에서와 같이 각 모델의 출력을 각 스텝에서 자체 피드백할 수 있어 이전 예측을 조건부로 예측을 수행할 수 있습니다.\n","\n","이 형태의 모델이 갖는 한 가지 분명한 장점은 다양한 길이의 출력을 생성하도록 설정할 수 있다는 것입니다.\n","\n","이 튜토리얼의 전반부에서 훈련한 단일 스텝 다중 출력 모델 중 하나를 가져와 자기 회귀 피드백 루프에서 실행할 수 있지만 여기서는 이를 수행하도록 명시적으로 훈련된 모델을 빌드하는 데 중점을 둘 것입니다.\n","\n","![Feedback a model's output to its input](https://www.tensorflow.org/tutorials/structured_data/images/multistep_autoregressive.png)\n"]},{"cell_type":"markdown","metadata":{"id":"PKRreBbULRXY"},"source":["#### RNN\n","\n","이 튜토리얼에서는 자기 회귀 RNN 모델만 빌드하지만 이 패턴은 단일 타임스텝을 출력하도록 설계된 모든 모델에 적용할 수 있습니다.\n","\n","이 모델은 단일 스텝 `LSTM` 모델과 기본 형태가 동일하여 `LSTM` 다음에 `LSTM` 출력을 모델 예측으로 변환하는 `layers.Dense`가 이어집니다.\n","\n","`layers.LSTM`은 상태와 시퀀스 결과를 자동으로 관리하는 더 높은 수준의 `layers.RNN`에서 래핑된 `layers.LSTMCell`입니다(자세한 내용은 [Keras RNN](https://www.tensorflow.org/guide/keras/rnn) 참조).\n","\n","이 경우 모델은 각 스텝에 대한 입력을 수동으로 관리해야 하므로 더 낮은 수준의 단일 타임스텝 인터페이스에 대해 `layers.LSTMCell`를 직접 사용합니다."]},{"cell_type":"code","metadata":{"id":"-hUlqHr2XmMu"},"source":["class FeedBack(tf.keras.Model):\n","    def __init__(self, units, out_steps):\n","        super().__init__()\n","        self.out_steps = out_steps\n","        self.units = units\n","        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n","        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n","        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n","        self.dense = tf.keras.layers.Dense(num_features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXdrS8VkfNzX"},"source":["feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vM2K_LLdRjDZ"},"source":["def warmup(self, inputs):\n","  # inputs.shape => (batch, time, features)\n","  # x.shape => (batch, lstm_units)\n","  x, *state = self.lstm_rnn(inputs)\n","\n","  # predictions.shape => (batch, features)\n","  prediction = self.dense(x)\n","  return prediction, state\n","\n","FeedBack.warmup = warmup"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6JkaSYaZ9eB7"},"source":["이 메서드는 단일 타임스텝 예측과 LSTM의 내부 상태를 반환합니다."]},{"cell_type":"code","metadata":{"id":"w9Fz6NTKXXwU"},"source":["prediction, state = feedback_model.warmup(multi_window.example[0])\n","prediction.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S_ZdvPjdX3y3"},"source":["`RNN`의 상태 및 초기 예측을 사용하여 이제 이전의 각 스텝에서 수행한 예측을 입력으로 제공하여 모델을 계속 반복할 수 있습니다.\n","\n","출력 예측을 수집하는 가장 간단한 방법은 Python 목록을 사용하고 루프 후에 `tf.stack`을 사용하는 것입니다."]},{"cell_type":"markdown","metadata":{"id":"yotTad3nZXQU"},"source":["참고: 이와 같이 Python 목록을 쌓는 것은 훈련을 위해 `Model.compile(..., run_eagerly=True)`를 사용하거나 고정 길이의 출력을 통해 즉시 실행하는 경우에만 효과가 있습니다. 동적 출력 길이의 경우 Python 목록 대신 `tf.TensorArray`를 사용하고 Python `range` 대신 `tf.range`를 사용해야 합니다."]},{"cell_type":"code","metadata":{"id":"g1GRDu3mZtr9"},"source":["def call(self, inputs, training=None):\n","  # Use a TensorArray to capture dynamically unrolled outputs.\n","  predictions = []\n","  # Initialize the lstm state\n","  prediction, state = self.warmup(inputs)\n","\n","  # Insert the first prediction\n","  predictions.append(prediction)\n","\n","  # Run the rest of the prediction steps\n","  for n in range(1, self.out_steps):\n","    # Use the last prediction as input.\n","    x = prediction\n","    # Execute one lstm step.\n","    x, state = self.lstm_cell(x, states=state,\n","                              training=training)\n","    # Convert the lstm output to a prediction.\n","    prediction = self.dense(x)\n","    # Add the prediction to the output\n","    predictions.append(prediction)\n","\n","  # predictions.shape => (time, batch, features)\n","  predictions = tf.stack(predictions)\n","  # predictions.shape => (batch, time, features)\n","  predictions = tf.transpose(predictions, [1, 0, 2])\n","  return predictions\n","\n","FeedBack.call = call"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ubop-YWp15XW"},"source":["예제 입력에서 이 모델을 테스트 실행합니다."]},{"cell_type":"code","metadata":{"id":"Xja83zEYaM2D"},"source":["print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qMs0rYB8be9M"},"source":["이제 모델을 훈련합니다."]},{"cell_type":"code","metadata":{"id":"VBRVG2hnNyrO"},"source":["history = compile_and_fit(feedback_model, multi_window)\n","\n","IPython.display.clear_output()\n","\n","multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n","multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n","multi_window.plot(feedback_model)"],"execution_count":null,"outputs":[]}]}